{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ERA5-SWVL1-SR : Downscale swvl1 from ERA5 resolution to ERA5-Land resolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray as xr\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import torchvision\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.style.use(\"seaborn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importation of libraries\n",
    "\n",
    "from models import Discriminator,Generator\n",
    "from train_model import SRGAN_training\n",
    "from plots import image_look_evaluation\n",
    "from datasets import SRDataset\n",
    "from evaluate_model import evaluate_model,evaluate_model_robustness\n",
    "from utils import create_model_folder_and_copy_json\n",
    "from downscale_era5_swvl1 import super_resolve_swvl1_world,super_resolve_swvl1_local_patch\n",
    "from rasters_manipulation import load_and_clean_raster"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_MODEL = False\n",
    "PLOT_METRICS = False\n",
    "CHECK_DATASET = False\n",
    "RESUME_TRAINING = False\n",
    "PLOT_SR_IMAGES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DISPLAY_DEMO = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path, configuration_path = create_model_folder_and_copy_json(model_path_parent= Path(\"models\"),\n",
    "                                resume_training=RESUME_TRAINING,\n",
    "                                train_model=TRAIN_MODEL,\n",
    "                                model_folder_path=Path(\"models/final_state/\"),\n",
    "                                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(configuration_path, 'r') as file:\n",
    "    configuration = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = configuration[\"dataloader\"][\"batch_size\"]\n",
    "NUM_WORKERS = configuration[\"dataloader\"][\"num_workers\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_res_image_dim = configuration[\"dataset\"][\"low_res_image_dim\"]\n",
    "high_res_image_dim = configuration[\"dataset\"][\"high_res_image_dim\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = configuration[\"training\"][\"alpha\"]\n",
    "generator_learning_rate = configuration[\"training\"][\"generator_learning_rate\"]\n",
    "discriminator_learning_rate = configuration[\"training\"][\"discriminator_learning_rate\"]\n",
    "number_of_epochs = configuration[\"training\"][\"number_of_epochs\"]\n",
    "pre_training = (configuration[\"training\"][\"pre_training\"])==\"True\"\n",
    "pre_train_number_of_epochs = configuration[\"training\"][\"pre_train_number_of_epochs\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Datasets, Preprocessing and Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_lr_data_path = Path(\"bucket_tensor/train/era5\")\n",
    "train_hr_data_path = Path(\"bucket_tensor/train/era5land\")\n",
    "\n",
    "test_lr_data_path = Path(\"bucket_tensor/test/era5\")\n",
    "test_hr_data_path = Path(\"bucket_tensor/test/era5land\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    train_dataset = SRDataset(lr_data_path=train_lr_data_path,hr_data_path=train_hr_data_path,\n",
    "                            low_res_image_dim=low_res_image_dim,high_res_image_dim=high_res_image_dim)\n",
    "    train_dataloader = torch.utils.data.dataloader.DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        drop_last=True,\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    eval_dataset = SRDataset(lr_data_path=test_lr_data_path,hr_data_path=test_hr_data_path,\n",
    "                            low_res_image_dim=low_res_image_dim,high_res_image_dim=high_res_image_dim)\n",
    "    eval_dataloader = torch.utils.data.dataloader.DataLoader(\n",
    "        eval_dataset,    \n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        num_workers=NUM_WORKERS,\n",
    "        drop_last=True,\n",
    "        pin_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECK_DATASET:\n",
    "    print(f\" * Dataset contains {len(train_dataset)} image(s).\")\n",
    "    for _, batch in enumerate(train_dataloader, 0):\n",
    "        lr_image, hr_image = batch\n",
    "        # lr_image=lr_image[0, ...].mul(255).byte()\n",
    "        # hr_image=hr_image[0, ...].mul(255).byte()\n",
    "        print(lr_image.shape)\n",
    "        print(hr_image.shape)\n",
    "        #print(lr_image[0, ...].mul(255).byte().shape)   \n",
    "        torchvision.io.write_png(lr_image[0, ...].repeat(3,1,1).mul(255).byte(), \"lr_image.png\")\n",
    "        torchvision.io.write_png(hr_image[0, ...].repeat(3,1,1).mul(255).byte(), \"hr_image.png\")\n",
    "        break # we deliberately break after one batch as this is just a test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "discriminator=Discriminator(low_res_size=low_res_image_dim)\n",
    "generator=Generator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL:\n",
    "    SRGAN_training(generator,discriminator,train_dataloader,model_path,\n",
    "                   alpha_=alpha,G_learning_rate=generator_learning_rate,\n",
    "                    D_learning_rate=discriminator_learning_rate,device=device,\n",
    "                    number_of_epochs=number_of_epochs,resume_training=RESUME_TRAINING,\n",
    "                    pre_training=pre_training,pre_train_number_of_epochs=pre_train_number_of_epochs)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator=Generator()\n",
    "checkpoint = torch.load(model_path)\n",
    "generator.load_state_dict(checkpoint['generator_state_dict'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL and PLOT_METRICS:\n",
    "    metrics_df = evaluate_model(generator,eval_dataloader,device)\n",
    "    metrics_df.plot(backend=\"plotly\").show()\n",
    "    display(metrics_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL and PLOT_METRICS:\n",
    "    n_metrics_df =  evaluate_model_robustness(generator,eval_dataloader, device,noise_power=0.05)\n",
    "    n_metrics_df.plot(backend=\"plotly\").show()\n",
    "    display(n_metrics_df.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TRAIN_MODEL and PLOT_SR_IMAGES:\n",
    "    image_look_evaluation(eval_dataloader,generator,nb_samples=50,device=\"cuda\",seed=890)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on new ERA5 raster\n",
    "\n",
    "Data with only one timestamp are currently supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5_raster = load_and_clean_raster(\"data/era5_31-12-2022.nc\",tolerance=1e-6)\n",
    "if DISPLAY_DEMO:\n",
    "    display(era5_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5land_raster = xr.open_dataset(\"data/era5land_31-12-2022.nc\")\n",
    "if DISPLAY_DEMO:\n",
    "    display(era5land_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "era5land_model_raster = super_resolve_swvl1_world(era5_raster,\"2022-12-31\",generator,device,BATCH_SIZE,NUM_WORKERS)\n",
    "if DISPLAY_DEMO:\n",
    "    display(era5land_model_raster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_era5land_array = super_resolve_swvl1_local_patch(generator,era5_raster,latitude=43.78,longitude=10.69,\n",
    "                                                       era5land_raster=era5land_raster,device=device,verbose=DISPLAY_DEMO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISPLAY_DEMO:\n",
    "    era5_raster.swvl1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISPLAY_DEMO:\n",
    "    era5land_raster.swvl1.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if DISPLAY_DEMO:\n",
    "    era5land_model_raster.swvl1.plot()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End of notebook"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "srgan-copernicus-kernel-new",
   "language": "python",
   "name": "srgan-copernicus-kernel-new"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
